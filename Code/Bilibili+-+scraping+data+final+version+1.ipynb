{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "import bs4\n",
    "import json\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import gensim\n",
    "import emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BilibiliWords = pd.read_csv('BilibiliWords.txt', \\\n",
    "                                header = None, delimiter=\"\\t\", quoting=3, error_bad_lines=False).loc[:,0].tolist()\n",
    "\n",
    "jieba.load_userdict(BilibiliWords)\n",
    "SChineseStopWords = pd.read_csv('ChineseStopwords.txt',\n",
    "                                     header = None, delimiter=\"\\t\", quoting=3, error_bad_lines=False).loc[:,0].tolist()\n",
    "\n",
    "\n",
    "SChineseStopWords += [' ',',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBLVData(video_url):\n",
    "    cid = None\n",
    "    r = requests.get(video_url)\n",
    "    if r is not None:\n",
    "        soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        #scrape A version\n",
    "        title = soup.find('div', class_ = 'v-title')\n",
    "        if title is not None:\n",
    "            vname = title.text\n",
    "            #video category\n",
    "            category = \"\"\n",
    "            aTags = soup.findAll('a', href=re.compile('/video'))\n",
    "            for aTag in aTags:\n",
    "                category = category + \"/\" + aTag.text\n",
    "                #unique ids\n",
    "                idstr = soup.find('div', class_ ='scontent').text\n",
    "                if re.search('cid=\\d+',idstr) is not None:\n",
    "                    cid = re.search('cid=\\d+',idstr).group()[4:]\n",
    "                    aid = re.search('aid=\\d+',idstr).group()[4:]\n",
    "        else:\n",
    "            TONGSHAWOYE1 = 'window.__INITIAL_STATE__='\n",
    "            TONGSHAWOYE2 = ';(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());'\n",
    "    \n",
    "            jsonTags = soup.findAll('script',type = False)\n",
    "            for jsonTag in jsonTags:\n",
    "                if jsonTag.text.startswith(TONGSHAWOYE1) and jsonTag.text.endswith(TONGSHAWOYE2):\n",
    "                    data = json.loads(jsonTag.text[25:-122])\n",
    "                    if 'aid' in data and 'videoData' in data:\n",
    "                        aid = data['aid']\n",
    "                        vname = str(data['videoData']['title'])\n",
    "                        cid = str(data['videoData']['pages'][0]['cid'])\n",
    "                        main_cat = \"/\"+data['videoData']['breadcrumb']['first']['name']\n",
    "                        sec_cat = \"/\"+data['videoData']['breadcrumb']['second']['name']\n",
    "                        category = main_cat + sec_cat + \"/高级弹幕\"\n",
    "        \n",
    "        if cid is not None:\n",
    "            bsxml = 'http://comment.bilibili.tv/'+ cid+'.xml'\n",
    "            bsr = requests.get(bsxml)\n",
    "            if bsr is not None:\n",
    "                bs_list = []\n",
    "                bssoup = bs4.BeautifulSoup(bsr.text, 'xml')\n",
    "                dTags = bssoup.findAll('d', p = True)\n",
    "                for dTag in dTags:\n",
    "                    bs_list.append(dTag.text)\n",
    "                return (vname, category, aid, cid, bs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rank(filename):\n",
    "    '''\n",
    "    Get a list of videos in the rank.\n",
    "    Input: filename - the name of the json file as a string\n",
    "    Example:\n",
    "        'all-3-0.json'\n",
    "    Return:\n",
    "        a list of aid of videos in the ranking\n",
    "    '''\n",
    "    aid_lst = []\n",
    "    rank = json.load(open(filename))\n",
    "    v_lst = rank['rank']['list']\n",
    "    for item in v_lst:\n",
    "        aid_lst.append(int(item['aid']))\n",
    "        if 'others' in item:\n",
    "            for other in item['others']:\n",
    "                aid_lst.append(int(other['aid']))\n",
    "    return aid_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanBStext(BStext):\n",
    "    loc = BStext.find('var names =')\n",
    "    if loc:\n",
    "        BStext = BStext[:loc]\n",
    "    return BStext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df(filename):\n",
    "    '''\n",
    "    Get the desired dataframe from the imported json file.\n",
    "    Example:\n",
    "        'all-3-0.json'\n",
    "    Return:\n",
    "        The desired dataframe from this json file.\n",
    "    '''\n",
    "    l = get_rank(filename)\n",
    "    parsDict = {'video_title':[], 'video_url':[], 'category':[], 'BS_text':[] }\n",
    "    for n in l:\n",
    "        time.sleep(2)\n",
    "        video_url = 'https://www.bilibili.com/video/av{}/'.format(n)\n",
    "        if getBLVData(video_url):\n",
    "            result = getBLVData(video_url)\n",
    "            parsDict['video_title'].append(result[0])\n",
    "            parsDict['video_url'].append(video_url)\n",
    "            parsDict['category'].append(result[1])\n",
    "            parsDict['BS_text'].append(result[4])\n",
    "    BLDF = pd.DataFrame(parsDict)\n",
    "    BLDF['main category'] = BLDF['category'].str.split('/').map(lambda x: x[1])\n",
    "    BLDF['sub category'] = BLDF['category'].str.split('/').map(lambda x: x[2])\n",
    "    BLDF['BS_text'] = BLDF['BS_text'].apply(lambda x: ''.join(x)).apply(lambda x: cleanBStext(x))\n",
    "    return BLDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Remove_SChinese_Stopwords(words, list_of_stopwords):\n",
    "    output = [word for word in words if word not in list_of_stopwords]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMOTICONS = emoticons.EMOTICONS\n",
    "\n",
    "def str_find_all(emot, bulletstr, start = 0, sub = None, lstps = None): \n",
    "    if lstps == None: \n",
    "        lstps = []\n",
    "    if sub == None: \n",
    "        sub = bulletstr\n",
    "    if emot not in sub: \n",
    "        return lstps\n",
    "    elif start >= len(bulletstr) - 1: \n",
    "        return lstps\n",
    "\n",
    "    else: \n",
    "        subpos = sub.find(emot)\n",
    "        pos = start + subpos\n",
    "        lstps.append(pos)\n",
    "        start = pos + 1\n",
    "        sub = bulletstr[start:]\n",
    "        lst_sub = str_find_all(emot, bulletstr, start, sub, lstps)\n",
    "\n",
    "        return lstps\n",
    "\n",
    "\n",
    "\n",
    "def jpemoticon(bulletstr): \n",
    "\n",
    "    dict_pos = {}\n",
    "\n",
    "    for emotlst in EMOTICONS: \n",
    "        for icon in EMOTICONS[emotlst]: \n",
    "            if icon in bulletstr: \n",
    "                positions = str_find_all(icon, bulletstr)\n",
    "                if icon in dict_pos: \n",
    "                    dict_pos[icon].extend(positions)\n",
    "                else: \n",
    "                    dict_pos[icon] = positions\n",
    "\n",
    "    return dict_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emot_find_all(emot, bulletstr, start = 0, sub = None, lstps = None): \n",
    "    if lstps == None: \n",
    "        lstps = []\n",
    "    if sub == None: \n",
    "        sub = bulletstr\n",
    "    if emot not in sub: \n",
    "        return lstps\n",
    "    elif start >= len(bulletstr) - 1: \n",
    "        return lstps\n",
    "\n",
    "    else: \n",
    "        subpos = sub.find(emot)\n",
    "        pos = start + subpos\n",
    "        end = pos + len(emot)\n",
    "        lstps.append((pos,end))\n",
    "        start = pos + 1\n",
    "        sub = bulletstr[start:]\n",
    "        lst_sub = emot_find_all(emot, bulletstr, start, sub, lstps)\n",
    "\n",
    "        return lstps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllEmoticons = sum(EMOTICONS.values(),[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Add_Emoticons = ['(╯‵□′)╯︵┻━┻',\n",
    "                 '( ゜-  ゜)つロ',\n",
    "                 '（￣▽￣）',\n",
    "                 '(• ̀ㅁ• ́;)',\n",
    "                 'ヾ(@^▽^@)ノ',\n",
    "                 '\\(≧▽≦)/',\n",
    "                 '(＾Ｕ＾)ノ',\n",
    "                 '( ﾟ ∀ ﾟ )',\n",
    "                 '(๑• ̀ㅂ• ́)و✧',\n",
    "                 '(´இ皿இ｀)',\n",
    "                 '(´◑д◐｀)',\n",
    "                 'q(^_^q=)>',\n",
    "                 '<(=p^_^)p',\n",
    "                 '(・^・╬)',\n",
    "                 '(ノ=Д=)ノ┻━┻',\n",
    "                 '(# ﾟД ﾟ)',\n",
    "                 '( ⊙  o  ⊙ )',\n",
    "                 '(ˉ﹃ˉ)',\n",
    "                 '_(:3」∠)_',\n",
    "                 '_(:з」∠)_',\n",
    "                 '(ﾉ´∀｀*)ノ',\n",
    "                 '(;゜ロ゜ノ)ノ',\n",
    "                 '(σ｀д′)σ',\n",
    "                 '(￣_,￣ )',\n",
    "                 '(￣ε(#￣)',\n",
    "                 '☆╰╮(￣▽￣///)',\n",
    "                 '░▒▓█▇▅▂∩(･ω･)∩▂▅▇█▓▒░',\n",
    "                 'o(╯□╰)o',\n",
    "                 '(ಥ_ಥ)',\n",
    "                 '(╯°Д°)╯︵┴┴',\n",
    "                 '*^_^*',\n",
    "                 '(;´༎ ຶД༎ ຶ`)',\n",
    "                 '←_←',\n",
    "                 '(๑• . •๑)',\n",
    "                 '*罒▽罒*',\n",
    "                 '(⑉°з°)-♡',\n",
    "                 'o(╯□╰)o',\n",
    "                 '(￢∀￢)σ',\n",
    "                 '＜（－︿－）＞',\n",
    "                 '( =①ω①=)',\n",
    "                 '( ⊙ o ⊙ )',\n",
    "                 '(ｏ  ‵-′)ノ”(ノ﹏<。)',\n",
    "                 '٩(*∂v∂*)۶',\n",
    "                 ' _(• ̀ω• ́」∠)_',\n",
    "                 'Σ（・□・；）',\n",
    "                 '╭(╯^╰)╮',\n",
    "                 '╭(￣▽￣)╮',\n",
    "                 'Σ(￣□￣||)',\n",
    "                 '(<ゝω·)☆',\n",
    "                 ' (๑• ̀ㅂ• ́)و✧',\n",
    "                 '(●´∇｀●)',\n",
    "                 '_:(´ཀ`」∠):_',\n",
    "                 '(๑‾ ᷆д‾ ᷇๑)',\n",
    "                 '( ๑ŏ  ﹏  ŏ๑ )',\n",
    "                 '(°ー°〃)',\n",
    "                 '(*+﹏+*)',\n",
    "                 '(^・ω・^  )',\n",
    "                 '～(￣▽￣～)',\n",
    "                 '(～￣▽￣)～',\n",
    "                 '(*^__^*)',\n",
    "                 '(^・ω・^  )',\n",
    "                 ' o(≧口≦)o']\n",
    "\n",
    "AllEmoticons += Add_Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smart_cut(string, patterns, user_dict = None):\n",
    "    output = []\n",
    "    str_start = 0\n",
    "    str_end = 0\n",
    "    \n",
    "    if isinstance(string, str):\n",
    "        all_positions = sum([emot_find_all(emot, string) for emot in AllEmoticons],[])\n",
    "        all_positions.sort()\n",
    "        \n",
    "        if user_dict is not None:\n",
    "            jieba.load_userdict(user_dict)\n",
    "            \n",
    "        if all_positions == []:\n",
    "            output = jieba.lcut(string)\n",
    "        else:\n",
    "            for pos in all_positions:\n",
    "                str_end = pos[0]\n",
    "                wordslist = jieba.lcut(string)[str_start:str_end]\n",
    "                output += wordslist\n",
    "                output.append(string[pos[0]:pos[1]])\n",
    "                str_start = pos[1]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_df(filename):\n",
    "    BLDF = get_df(filename)\n",
    "    BLDF['segmented'] = BLDF['BS_text'].astype(str).apply(jieba.lcut)\n",
    "    BLDF['clean_text'] = BLDF['segmented'].apply(Remove_SChinese_Stopwords,\n",
    "                                             list_of_stopwords = SChineseStopWords)\n",
    "    BLDF['Smart_Cutted'] = BLDF['BS_text'].apply(smart_cut, patterns = AllEmoticons, user_dict = BilibiliWords)\n",
    "    BLDF['normalized_words'] = BLDF['Smart_Cutted'].apply(Remove_SChinese_Stopwords,\n",
    "                                                      list_of_stopwords = SChineseStopWords)\n",
    "    taggedDocs = []\n",
    "    for index, row in BLDF.iterrows():\n",
    "        #Just doing a simple keyword assignment\n",
    "        docKeywords = []#s for s in keywords if s in row['normalized_words']\n",
    "        docKeywords.append(row['video_title'])\n",
    "        docKeywords.append(row['category'])\n",
    "        taggedDocs.append(gensim.models.doc2vec.TaggedDocument(words = row['normalized_words'], tags = docKeywords))\n",
    "    BLDF['TaggedText'] = taggedDocs\n",
    "    return BLDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_list = ['动画all-30-1.json', '国创相关all-30-168.json', '娱乐all-30-5.json', '影视all-30-181.json', \\\n",
    "                '时尚all-30-155.json', '游戏all-30-4.json', '生活all-30-160.json', '科技all-30-36.json', \\\n",
    "                '舞蹈all-30-129.json', '音乐all-30-3.json', '鬼畜all-30-119.json']\n",
    "for filename in filename_list:\n",
    "    BLDF = final_df(filename)\n",
    "    BLDF.to_csv('/Users/apple/Desktop/BLData{}.txt'.format(filename[0: 2]), header = True, index = None, sep = \"|\", mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
